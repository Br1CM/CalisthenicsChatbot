{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6923e68a-fde3-4cba-9faa-d1e1bb54a210",
   "metadata": {},
   "source": [
    "# Video Augmentation\n",
    "\n",
    "Este notebook está destinado a la automatización del proceso de Data augmentation aplicado a los vídeos, pues es la fuente de datos para nuestro primer modelo de clasificación. Este método conseguirá agrandar la cantidad de training data que podemos aportar al modelo para evitar tanto el overfitting como para intentar que el modelo pueda obtener buen accuracy sin necesidad de tener la mejor data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a94b588-c217-4905-b910-38f19688f92d",
   "metadata": {},
   "source": [
    "## Problemas del Pose Tracking\n",
    "\n",
    "Este tipo de modelizado de una persona en 2D en base a un video aportado al modelo es el método seleccionado para intentar estudiar la estructura del cuerpo de la persona del video, pero este modelizado puede fallar por diversas razones: Los videos que la gente puede pasar pueden tener ángulos que no den pie a detectar bien el cuerpo, teniendo objetos de por medio, con condiciones de luz escasas que den problemas para distinguir a la persona, etc. \n",
    "Es por ello que se intentará que el modelo funcione mejor gracias a tener muchos datos \"malos\" que sepa que tiene que reconocer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cecbf2b-d979-4e71-ab3b-a9a856088569",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caf6aeca-15ec-48ae-8fc8-8272661c78ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import vidaug.augmentors as va\n",
    "from PIL import Image, ImageSequence\n",
    "workpath = 'C:/Users/Legion/TFM/Tareas'\n",
    "os.chdir(workpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d82b406-a469-4451-b79d-dd80751616ad",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97b6766e-a789-45cd-947b-45c438ae30e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_loader(video_path):\n",
    "    # Abrir el video con OpenCV\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    success, image = vidcap.read()\n",
    "    \n",
    "    while success:\n",
    "        # Convertir cada frame de BGR (formato OpenCV) a RGB (formato Pillow)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # Convertir el frame a un objeto PIL.Image.Image\n",
    "        pil_image = Image.fromarray(image_rgb)\n",
    "        frames.append(pil_image)\n",
    "        # Leer el siguiente frame\n",
    "        success, image = vidcap.read()\n",
    "    \n",
    "    vidcap.release()\n",
    "    return frames\n",
    "\n",
    "\n",
    "def frames_to_video(frames, output_path, fps=30):\n",
    "    if not frames:\n",
    "        print(\"No hay frames para escribir en el video.\")\n",
    "        return\n",
    "\n",
    "    # Obtener el tamaño de los frames\n",
    "    frame_size = frames[0].size  # (width, height)\n",
    "    frame_width, frame_height = frame_size\n",
    "\n",
    "    # Crear el VideoWriter\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codificación para MP4\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    for i, frame in enumerate(frames):\n",
    "        # Convertir el frame de PIL.Image a un array de NumPy\n",
    "        frame_np = cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR)\n",
    "        # Escribir el frame en el video\n",
    "        out.write(frame_np)\n",
    "\n",
    "    # Liberar el VideoWriter\n",
    "    out.release()\n",
    "    print(f\"Video guardado en {output_path}\")\n",
    "\n",
    "def frames_to_gif(frames, output_path, duration=100):\n",
    "    if not frames:\n",
    "        print(\"No hay frames para escribir en el GIF.\")\n",
    "        return\n",
    "\n",
    "    # Convertir los frames a objetos PIL.Image\n",
    "    pil_images = [frame.convert(\"RGB\") for frame in frames]\n",
    "\n",
    "    # Guardar como GIF\n",
    "    pil_images[0].save(\n",
    "        output_path,\n",
    "        save_all=True,\n",
    "        append_images=pil_images[1:],\n",
    "        duration=duration,\n",
    "        loop=0\n",
    "    )\n",
    "    print(f\"GIF guardado en {output_path}\")\n",
    "\n",
    "def create_new_video(video):\n",
    "    prob100 = lambda aug: va.Sometimes(1, aug) # Used to apply augmentor with 100% probability\n",
    "    prob80 = lambda aug: va.Sometimes(0.8, aug) # Used to apply augmentor with 80% probability\n",
    "    prob60 = lambda aug: va.Sometimes(0.6, aug) # Used to apply augmentor with 60% probability\n",
    "    prob50 = lambda aug: va.Sometimes(0.5, aug) # Used to apply augmentor with 50% probability\n",
    "    prob30 = lambda aug: va.Sometimes(0.3, aug) # Used to apply augmentor with 30% probability\n",
    "    seq = va.Sequential([ \n",
    "        prob100(va.HorizontalFlip()), # horizontally flip the video with 100% probability\n",
    "        prob30(va.Pepper()), # Pepper Noise added 30% probability\n",
    "        prob30(va.Salt()), # Salt Noise added 30% probability\n",
    "        prob80(va.RandomRotate(random.randint(15, 30))), # Rotation between 15 and 30 degrees, 30% probability\n",
    "    ])\n",
    "    return seq(video)\n",
    "\n",
    "def pipeline_augmentation(input_video_path, output_dir_path):\n",
    "    video_name = input_video_path.split('/')\n",
    "    name = video_name[-1].split('.')\n",
    "    input_frames = video_loader(input_video_path)\n",
    "    for num in range(4):\n",
    "        new_video = create_new_video(input_frames)\n",
    "        frames_to_video(new_video, output_dir_path+'/'+name[0]+'_'+str(num)+'.mp4')\n",
    "    print('Videos augmented succesfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "198d75d7-e385-4b59-bfe0-78b0a981c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = os.listdir(workpath+'/VideosTR/VideosAug')\n",
    "abs_paths_videos = [workpath+'/VideosTR/VideosAug/'+x for x in videos if '.' in x]\n",
    "out_path = workpath+'/VideosTR/VideosAug'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b70fd0b-3821-4d45-9593-74dc9a8d9ed8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for video in abs_paths_videos:\n",
    "    pipeline_augmentation(video, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4547f32-4c2f-4cac-bfa4-ff8d5c2563b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
