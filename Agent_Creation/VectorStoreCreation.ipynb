{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35a9c9a",
   "metadata": {},
   "source": [
    "# Creación del modelo de chat\n",
    "\n",
    "En este notebook crearemos un RAG partiendo de una base de documentos intercalados entre webs de dominio accesible de manera gratuita y articulos de ciencia del deporte (también de dominio público).\n",
    "\n",
    "**IMPORTANTE**: En este Notebook se han utilizado recursos como _FireCrawl_ y _LlamaParse_ que requieren de claves API para su uso. Estas se han eliminado a fin de subir este archivo al repositorio de GitHub y que se pueda visitar sin exponer estas mismas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bc5934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "workpath = 'C:/Users/Legion/TFM/Tareas'\n",
    "os.chdir(workpath)\n",
    "from firecrawl import FirecrawlApp\n",
    "import json\n",
    "from llama_parse import LlamaParse\n",
    "import nest_asyncio\n",
    "import pickle\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e9b883",
   "metadata": {},
   "source": [
    "## Compilacion de data para el vector store\n",
    "\n",
    "El primer paso para crear la RAG es tener un vector store donde se guarde la información relacionada con nuestro tema para que el modelo sea capaz de responder preguntas. En este caso, comenzaremos pasando las múltiples fuentes de información que tenemos a markdown, con tal de poder embedir estos documentos.\n",
    "\n",
    "#### Información contenida en Webs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eafea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear app para web-scraping\n",
    "scrape_app = FirecrawlApp(api_key='------APIKEY------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d404a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = pd.read_table('./Docs/URLs.txt')['URLS'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3302ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_docs = [scrape_app.scrape_url(url) for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ad0c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(url_docs)):\n",
    "    with open(f'./Docs/webs/documenst({i}).json', \"w\") as json_file:\n",
    "        json.dump(url_docs[i], json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a05bfa",
   "metadata": {},
   "source": [
    "### Información contenida en pdfs\n",
    "#### Articulos científicos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43971c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f62066",
   "metadata": {},
   "outputs": [],
   "source": [
    "articulos_pdf = os.listdir('./Docs/Articles/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3a346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for articulo in articulos_pdf:\n",
    "    pdfs.append(LlamaParse(api_key='------APIKEY------', result_type='markdown', parsing_instruction='''\n",
    "    This document is a scientific article.\n",
    "    Tipically, this documents have the title, authors, and then an abstract explaining the whole document at first in a summarization.\n",
    "    After this abstract, the documents are written with multiple columns.\n",
    "    Images and tables can be ignored.\n",
    "    ''').load_data('./Docs/Articles/'+articulo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9696a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdfs)):\n",
    "    with open(f'./Docs/Markdowns/articulo_{i}.pickle', 'wb') as file:\n",
    "        pickle.dump(pdfs[i], file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3e9a44",
   "metadata": {},
   "source": [
    "#### Artículos y libros (escritos a página entera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4593d11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "libros = os.listdir('./Docs/Books/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22432ab1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "libro1 = LlamaParse(api_key='------APIKEY------', result_type='markdown', parsing_instruction='''\n",
    "    This document is in spanish.\n",
    "    Images and tables can be ignored.\n",
    "    ''').load_data('./Docs/Books/'+libros[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e855344",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for libro in libros:\n",
    "    libros_parsed.append(LlamaParse(api_key='------APIKEY------', result_type='markdown', parsing_instruction='''\n",
    "    This document is about training and excercise.\n",
    "    Images and tables can be ignored.\n",
    "    ''').load_data('./Docs/Books/'+libro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cf9990",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(libros_parsed)):\n",
    "    with open(f'./Docs/Markdowns/libro_{i}.pickle', 'wb') as file:\n",
    "        pickle.dump(libros_parsed[i], file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18448da5",
   "metadata": {},
   "source": [
    "### Juntar toda la informacion y crear chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a59064",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_webs = []\n",
    "webs_path = os.listdir('./Docs/webs/')\n",
    "for path in webs_path:\n",
    "    with open(f'./Docs/webs/{path}', 'r', encoding='utf-8') as file:\n",
    "        web = json.load(file)\n",
    "    lista_webs.append(web[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bae9ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_webs[0]['docs'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471a3e37",
   "metadata": {},
   "source": [
    "#### Crear chunks de los documentos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e47d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2048,  # Adjust chunk size as needed\n",
    "    chunk_overlap=200  # Overlap between chunks to maintain context\n",
    ")\n",
    "\n",
    "web_splits = []\n",
    "for web in lista_webs:\n",
    "    web_splits.append(text_splitter.split_text(web['docs'][0]['markdown']))\n",
    "\n",
    "web_chunks = [item for sublist in web_splits for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68eef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_chunks[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a52f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "libros_list = [item.text for sublist in libros_parsed for item in sublist if len(item.text) < 2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65619cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "libros_chunks = [text_splitter.split_text(i) for i in [item.text for sublist in libros_parsed for item in sublist if len(item.text) > 2048]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e93493",
   "metadata": {},
   "outputs": [],
   "source": [
    "libros_chunks_unwrapped = [item for sublist in libros_chunks for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a886a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in libros_list:\n",
    "    libros_chunks_unwrapped.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6419d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "articulos_list = [item.text for sublist in pdfs for item in sublist if len(item.text) < 2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cb4de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "articulos_chunks = [text_splitter.split_text(i) for i in [item.text for sublist in pdfs for item in sublist if len(item.text) > 2048]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a125aab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "articulos_chunks_unwrapped = [item for sublist in articulos_chunks for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff6d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in articulos_list:\n",
    "    articulos_chunks_unwrapped.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c612bdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = web_chunks + libros_chunks_unwrapped + articulos_chunks_unwrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a198ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./Docs/Markdowns/Chunks_all.pickle', 'wb') as file:\n",
    "        pickle.dump(all_docs, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff164c4",
   "metadata": {},
   "source": [
    "## Crear vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e483b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./Docs/Markdowns/Chunks_all.pickle', 'rb') as file:\n",
    "    all_docs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501e5305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usar modelo de embedido multilingüe para embedir los chunks de documentos\n",
    "\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "embeddings = model.encode(all_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac29b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./Docs/Markdowns/Embedded_chunks.pickle', 'wb') as file:\n",
    "        pickle.dump(embeddings, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7129669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./Docs/Markdowns/Embedded_chunks.pickle', 'rb') as file:\n",
    "    embeddings = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85742475",
   "metadata": {},
   "source": [
    "**IMPORTANTE:** Se debe usar el mismo modelo de embeddings que se usa para crear el vector store como para el programa, a fin de evitar que falle el modelo RAG en un final. Si se cambia uno, hay que cambiarlos todos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46b4a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los embeddings a array de numpy\n",
    "embeddings = np.array(embeddings)\n",
    "\n",
    "# Crear un index (vector store)\n",
    "dimension = embeddings.shape[1]  # Dimensión de los embeddings\n",
    "index = faiss.IndexFlatL2(dimension)  # Tipo de índice (vector store)\n",
    "\n",
    "# Añadir los embeddings al vector store\n",
    "index.add(embeddings)\n",
    "\n",
    "# Guardar el vector store en local\n",
    "faiss.write_index(index, \"vector_store.index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafd47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba de funcionamiento\n",
    "question = \"¿Cómo hacer una dominada?\"\n",
    "query_vector = model.encode([question])[0]\n",
    "D, I = index.search(np.array([query_vector]), k=5)  # Busca los 5 chunks más cercanos a la pregunta\n",
    "\n",
    "# D tiene la informacion de las distancias, I los índices de los vectores\n",
    "# (Habrá que tener cargados tanto el vector store como los chunks sin embedir para visualizar el resultado)\n",
    "closest_docs = [all_docs[i] for i in I[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f24fe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b00d42",
   "metadata": {},
   "source": [
    "### Creación de las funciones para el uso del vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dc930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(docspath):\n",
    "    with open(docspath, 'rb') as file:\n",
    "        all_docs = pickle.load(file)\n",
    "    model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "    embeddings = np.array(model.encode(all_docs))\n",
    "    dimension = embeddings.shape[1]  # Dimension of the embeddings\n",
    "    index = faiss.IndexFlatL2(dimension)  # L2 distance index\n",
    "\n",
    "    # Add embeddings to the index\n",
    "    index.add(embeddings)\n",
    "\n",
    "    # Save index to disk (optional)\n",
    "    faiss.write_index(index, docspath+\"/vector_store.index\")\n",
    "\n",
    "def load_vector_store(path):\n",
    "    return faiss.read_index(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
